{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678d3243",
        "outputId": "451a9610-3806-4406-edcd-697cd9227d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".env file created successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create an empty .env file\n",
        "with open('.env', 'w') as f:\n",
        "    pass  # The 'pass' statement does nothing, effectively creating an empty file\n",
        "\n",
        "print(\".env file created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2a087e6",
        "outputId": "039bbcba-89e1-4bf1-9ecd-058d428c6849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy Gemini API key added to .env file.\n"
          ]
        }
      ],
      "source": [
        "# Add a dummy value for the Gemini API key to the .env file\n",
        "with open('.env', 'a') as f:\n",
        "    f.write('GOOGLE_API_KEY=\"\"')\n",
        "\n",
        "print(\"Dummy Gemini API key added to .env file.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '//content/feisty-outrider-471302-k6-597fcfaf6c32.json'"
      ],
      "metadata": {
        "id": "t0gAFmedos9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install google-cloud-speech"
      ],
      "metadata": {
        "id": "1M5k1Q_QpARQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-speech youtube_transcript_api"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGKXZmbOpB3A",
        "outputId": "421e54fc-570c-4883-ecfb-a5a0ff697612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-speech in /usr/local/lib/python3.12/dist-packages (2.33.0)\n",
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-1.2.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-speech) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-speech) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-speech) (5.29.5)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube_transcript_api) (2.32.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-speech) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-speech) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-speech) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-speech) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (2025.8.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-speech) (0.6.1)\n",
            "Downloading youtube_transcript_api-1.2.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.0/485.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "OPymXEgYMdkR",
        "outputId": "cbe19e2a-b002-4a57-8eab-58565877838a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.7)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.10-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, requests, pytube, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, dataclasses-json, google-ai-generativelanguage, langchain-google-genai, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.12.0 filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-community-0.3.29 langchain-google-genai-2.1.10 marshmallow-3.26.1 mypy-extensions-1.1.0 pytube-15.0.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "1515c3d1896a4b62a0156b8c5baff2fb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain langchain-google-genai langchain-community sentence-transformers faiss-cpu python-dotenv pydantic pytube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install yt-dlp SpeechRecognition pydub\n",
        "!apt update && apt install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qCws5vVxdwlh",
        "outputId": "aa5df6f6-6c34-4c61-9bc4-9371d0f88532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.9.5-py3-none-any.whl.metadata (177 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m174.1/177.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from SpeechRecognition) (4.15.0)\n",
            "Downloading yt_dlp-2025.9.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3 yt-dlp-2025.9.5\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,002 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [80.4 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,241 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,580 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,791 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [43.0 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,623 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,272 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,310 kB]\n",
            "Fetched 24.4 MB in 8s (3,183 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "csBSHBh0ExxU",
        "outputId": "941a5822-c03b-4f75-d305-10233197c454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Audio processing (pydub) available\n",
            "✅ Google Cloud Speech-to-Text available\n",
            "✅ Google Colab file upload available\n",
            "🔧 Initializing HuggingFace embeddings...\n",
            "✅ Embeddings initialized successfully!\n",
            "✅ Cell 1 Complete: Audio upload and processing system loaded!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 1: Audio Upload and Processing System - Core Classes\n",
        "import os\n",
        "import hashlib\n",
        "import json\n",
        "import logging\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "import math\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from pydantic import BaseModel, Field\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Audio processing libraries\n",
        "try:\n",
        "    from pydub import AudioSegment\n",
        "    from pydub.utils import which\n",
        "    AUDIO_PROCESSING_AVAILABLE = True\n",
        "    print(\"✅ Audio processing (pydub) available\")\n",
        "except ImportError:\n",
        "    print(\"⚠️ pydub not installed. Run: pip install pydub\")\n",
        "    AUDIO_PROCESSING_AVAILABLE = False\n",
        "\n",
        "# Google Cloud Speech\n",
        "try:\n",
        "    from google.cloud import speech\n",
        "    GOOGLE_CLOUD_SPEECH_AVAILABLE = True\n",
        "    print(\"✅ Google Cloud Speech-to-Text available\")\n",
        "except ImportError:\n",
        "    print(\"⚠️ Google Cloud Speech not available. Run: pip install google-cloud-speech\")\n",
        "    GOOGLE_CLOUD_SPEECH_AVAILABLE = False\n",
        "\n",
        "# HuggingFace embeddings\n",
        "try:\n",
        "    from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "    EMBEDDINGS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"⚠️ sentence-transformers not installed. Run: pip install sentence-transformers\")\n",
        "    EMBEDDINGS_AVAILABLE = False\n",
        "\n",
        "# File upload for Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    COLAB_AVAILABLE = True\n",
        "    print(\"✅ Google Colab file upload available\")\n",
        "except ImportError:\n",
        "    COLAB_AVAILABLE = False\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/.env')\n",
        "\n",
        "# Initialize the Gemini LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.3,\n",
        "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
        ")\n",
        "\n",
        "# Initialize embeddings\n",
        "if EMBEDDINGS_AVAILABLE:\n",
        "    print(\"🔧 Initializing HuggingFace embeddings...\")\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "    print(\"✅ Embeddings initialized successfully!\")\n",
        "else:\n",
        "    embeddings = None\n",
        "\n",
        "# Structured output models\n",
        "class AudioAnalysis(BaseModel):\n",
        "    audio_title: str = Field(description=\"Title or name of the audio file\")\n",
        "    main_topics: List[str] = Field(description=\"Main topics discussed in the audio\")\n",
        "    content_type: str = Field(description=\"Type of content (lecture, interview, meeting, etc.)\")\n",
        "    speakers: List[str] = Field(description=\"Identified speakers or voices\")\n",
        "    audio_quality: str = Field(description=\"Quality assessment of the audio\")\n",
        "\n",
        "class AudioChunkSummary(BaseModel):\n",
        "    start_time: str = Field(description=\"Start timestamp of the chunk\")\n",
        "    end_time: str = Field(description=\"End timestamp of the chunk\")\n",
        "    key_points: List[str] = Field(description=\"Key points discussed in this chunk\")\n",
        "    detailed_summary: str = Field(description=\"Comprehensive summary of the chunk content\")\n",
        "    topics_covered: List[str] = Field(description=\"Specific topics covered in this chunk\")\n",
        "\n",
        "# Audio utility functions\n",
        "def format_duration(seconds: float) -> str:\n",
        "    \"\"\"Convert seconds to HH:MM:SS format\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "\n",
        "    if hours > 0:\n",
        "        return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
        "    else:\n",
        "        return f\"{minutes:02d}:{secs:02d}\"\n",
        "\n",
        "def get_audio_info(audio_path: str) -> Dict:\n",
        "    \"\"\"Get basic audio file information\"\"\"\n",
        "    try:\n",
        "        if AUDIO_PROCESSING_AVAILABLE:\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            return {\n",
        "                'duration_seconds': len(audio) / 1000.0,\n",
        "                'duration_formatted': format_duration(len(audio) / 1000.0),\n",
        "                'channels': audio.channels,\n",
        "                'frame_rate': audio.frame_rate,\n",
        "                'sample_width': audio.sample_width,\n",
        "                'file_size_mb': os.path.getsize(audio_path) / (1024 * 1024)\n",
        "            }\n",
        "        else:\n",
        "            file_size = os.path.getsize(audio_path)\n",
        "            return {\n",
        "                'file_size_mb': file_size / (1024 * 1024),\n",
        "                'duration_seconds': 0,\n",
        "                'duration_formatted': 'Unknown'\n",
        "            }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error getting audio info: {e}\")\n",
        "        return {'error': str(e)}\n",
        "\n",
        "def get_audio_properties(audio_path: str) -> Dict:\n",
        "    \"\"\"Get audio file properties including sample rate\"\"\"\n",
        "    try:\n",
        "        if AUDIO_PROCESSING_AVAILABLE:\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            return {\n",
        "                'sample_rate': audio.frame_rate,\n",
        "                'channels': audio.channels,\n",
        "                'duration_ms': len(audio),\n",
        "                'sample_width': audio.sample_width\n",
        "            }\n",
        "        else:\n",
        "            return {'sample_rate': 16000}  # fallback\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to get audio properties: {e}\")\n",
        "        return {'sample_rate': 16000}  # fallback\n",
        "\n",
        "# Enhanced Audio Processing Manager\n",
        "class AudioProcessingManager:\n",
        "    def __init__(self, embeddings, cache_dir: str = \"./audio_cache\"):\n",
        "        self.embeddings = embeddings\n",
        "        self.cache_dir = cache_dir\n",
        "        self.audio_stores: Dict[str, FAISS] = {}  # filename -> FAISS store\n",
        "        self.audio_metadata: Dict[str, Dict] = {}  # filename -> metadata\n",
        "        self.audio_hashes: Dict[str, str] = {}  # filename -> content hash\n",
        "        self.merged_store: Optional[FAISS] = None\n",
        "        self.current_files: List[str] = []\n",
        "\n",
        "        # Create cache directory\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "        # Load existing cache\n",
        "        self._load_cache()\n",
        "\n",
        "    def _load_cache(self):\n",
        "        \"\"\"Load cached metadata\"\"\"\n",
        "        cache_file = os.path.join(self.cache_dir, \"audio_cache_metadata.json\")\n",
        "        if os.path.exists(cache_file):\n",
        "            try:\n",
        "                with open(cache_file, 'r') as f:\n",
        "                    cache_data = json.load(f)\n",
        "                    self.audio_hashes = cache_data.get('audio_hashes', {})\n",
        "                    self.audio_metadata = cache_data.get('audio_metadata', {})\n",
        "                    self.current_files = cache_data.get('current_files', [])\n",
        "                logger.info(f\"📋 Loaded cache with {len(self.audio_hashes)} audio entries\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Failed to load cache: {e}\")\n",
        "\n",
        "    def _save_cache(self):\n",
        "        \"\"\"Save cache metadata\"\"\"\n",
        "        cache_file = os.path.join(self.cache_dir, \"audio_cache_metadata.json\")\n",
        "        try:\n",
        "            cache_data = {\n",
        "                'audio_hashes': self.audio_hashes,\n",
        "                'audio_metadata': self.audio_metadata,\n",
        "                'current_files': self.current_files,\n",
        "                'last_updated': datetime.now().isoformat()\n",
        "            }\n",
        "            with open(cache_file, 'w') as f:\n",
        "                json.dump(cache_data, f, indent=2)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to save cache: {e}\")\n",
        "\n",
        "    def _get_safe_filename(self, filename: str) -> str:\n",
        "        \"\"\"Generate safe filename from original name\"\"\"\n",
        "        return hashlib.md5(filename.encode()).hexdigest()\n",
        "\n",
        "    def upload_audio_file(self) -> Optional[str]:\n",
        "        \"\"\"Upload audio file using Colab file upload\"\"\"\n",
        "        if not COLAB_AVAILABLE:\n",
        "            print(\"❌ File upload not available outside Google Colab\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            print(\"📁 Please select your audio file (MP3, WAV, M4A, etc.)\")\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            if not uploaded:\n",
        "                return None\n",
        "\n",
        "            filename = list(uploaded.keys())[0]\n",
        "            logger.info(f\"📁 Uploaded file: {filename}\")\n",
        "\n",
        "            # Get audio info\n",
        "            audio_info = get_audio_info(filename)\n",
        "            logger.info(f\"🎵 Audio info: {audio_info}\")\n",
        "\n",
        "            return filename\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Upload failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def split_large_audio(self, audio_path: str, max_chunk_mb: float = 8.0,\n",
        "                         chunk_duration_minutes: int = 10) -> List[str]:\n",
        "        \"\"\"Split large audio files into manageable chunks preserving sample rate\"\"\"\n",
        "        if not AUDIO_PROCESSING_AVAILABLE:\n",
        "            raise Exception(\"Audio processing not available\")\n",
        "\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n",
        "            duration_minutes = len(audio) / (1000 * 60)\n",
        "\n",
        "            logger.info(f\"🎵 Audio: {duration_minutes:.1f} min, {file_size_mb:.1f} MB, {audio.frame_rate} Hz\")\n",
        "\n",
        "            # Determine if splitting is needed\n",
        "            chunk_duration_ms = chunk_duration_minutes * 60 * 1000\n",
        "\n",
        "            if file_size_mb <= max_chunk_mb and duration_minutes <= chunk_duration_minutes:\n",
        "                logger.info(\"📁 File size acceptable, no splitting needed\")\n",
        "                return [audio_path]\n",
        "\n",
        "            # Calculate optimal chunk size\n",
        "            total_duration_ms = len(audio)\n",
        "            num_chunks = max(\n",
        "                math.ceil(file_size_mb / max_chunk_mb),\n",
        "                math.ceil(total_duration_ms / chunk_duration_ms)\n",
        "            )\n",
        "\n",
        "            chunk_size_ms = total_duration_ms // num_chunks\n",
        "            overlap_ms = 5000  # 5 second overlap\n",
        "\n",
        "            logger.info(f\"🔄 Splitting into {num_chunks} chunks of ~{chunk_size_ms/60000:.1f} minutes each\")\n",
        "\n",
        "            chunks = []\n",
        "            base_name = os.path.splitext(audio_path)[0]\n",
        "\n",
        "            for i in range(num_chunks):\n",
        "                start_ms = max(0, i * chunk_size_ms - (overlap_ms if i > 0 else 0))\n",
        "                end_ms = min(total_duration_ms, (i + 1) * chunk_size_ms + overlap_ms)\n",
        "\n",
        "                chunk = audio[start_ms:end_ms]\n",
        "                chunk_filename = f\"{base_name}_chunk_{i+1:02d}.wav\"\n",
        "\n",
        "                # Export as WAV preserving original sample rate (don't force 16kHz)\n",
        "                chunk.export(chunk_filename, format=\"wav\", parameters=[\n",
        "                    \"-ar\", str(audio.frame_rate),  # Use original sample rate\n",
        "                    \"-ac\", \"1\"  # Convert to mono\n",
        "                ])\n",
        "                chunks.append(chunk_filename)\n",
        "\n",
        "                logger.info(f\"✅ Created chunk {i+1}/{num_chunks}: {format_duration(start_ms/1000)} - {format_duration(end_ms/1000)}\")\n",
        "\n",
        "            return chunks\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Audio splitting failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def transcribe_audio_chunks(self, audio_chunks: List[str], file_identifier: str) -> Tuple[List[Document], str]:\n",
        "        \"\"\"Transcribe multiple audio chunks using Google Cloud Speech-to-Text with dynamic sample rate\"\"\"\n",
        "        if not GOOGLE_CLOUD_SPEECH_AVAILABLE:\n",
        "            return self._create_sample_documents(file_identifier), \"sample\"\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"🎤 Transcribing {len(audio_chunks)} audio chunks...\")\n",
        "\n",
        "            client = speech.SpeechClient()\n",
        "            all_transcripts = []\n",
        "\n",
        "            for i, chunk_path in enumerate(audio_chunks):\n",
        "                logger.info(f\"🎤 Processing chunk {i+1}/{len(audio_chunks)}: {os.path.basename(chunk_path)}\")\n",
        "\n",
        "                try:\n",
        "                    # Get audio properties for this chunk\n",
        "                    audio_props = get_audio_properties(chunk_path)\n",
        "                    sample_rate = audio_props['sample_rate']\n",
        "\n",
        "                    logger.info(f\"🔊 Detected sample rate: {sample_rate} Hz\")\n",
        "\n",
        "                    with open(chunk_path, 'rb') as audio_file:\n",
        "                        content = audio_file.read()\n",
        "\n",
        "                    audio = speech.RecognitionAudio(content=content)\n",
        "                    config = speech.RecognitionConfig(\n",
        "                        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "                        sample_rate_hertz=sample_rate,  # Use detected sample rate\n",
        "                        language_code=\"en-US\",\n",
        "                        enable_automatic_punctuation=True,\n",
        "                        enable_word_time_offsets=False,\n",
        "                    )\n",
        "\n",
        "                    # Use appropriate recognition method based on file size\n",
        "                    file_size_mb = os.path.getsize(chunk_path) / (1024 * 1024)  # Fixed: use file size, not content size\n",
        "\n",
        "                    if file_size_mb > 5:\n",
        "                        operation = client.long_running_recognize(config=config, audio=audio)\n",
        "                        response = operation.result(timeout=300)\n",
        "                    else:\n",
        "                        response = client.recognize(config=config, audio=audio)\n",
        "\n",
        "                    # Extract transcript from this chunk\n",
        "                    chunk_transcript = \"\"\n",
        "                    for result in response.results:\n",
        "                        chunk_transcript += result.alternatives[0].transcript + \" \"\n",
        "\n",
        "                    if chunk_transcript.strip():\n",
        "                        all_transcripts.append({\n",
        "                            'chunk_index': i + 1,\n",
        "                            'transcript': chunk_transcript.strip(),\n",
        "                            'file_path': chunk_path,\n",
        "                            'sample_rate': sample_rate\n",
        "                        })\n",
        "                        logger.info(f\"✅ Chunk {i+1} transcribed: {len(chunk_transcript)} characters\")\n",
        "                    else:\n",
        "                        logger.warning(f\"⚠️ Chunk {i+1} produced no transcript\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"❌ Failed to transcribe chunk {i+1}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            if not all_transcripts:\n",
        "                raise Exception(\"No successful transcriptions from any chunks\")\n",
        "\n",
        "            # Combine all transcripts\n",
        "            full_transcript = \" \".join([t['transcript'] for t in all_transcripts])\n",
        "\n",
        "            # Create document\n",
        "            doc = Document(\n",
        "                page_content=full_transcript,\n",
        "                metadata={\n",
        "                    'source': file_identifier,\n",
        "                    'total_chunks': len(audio_chunks),\n",
        "                    'successful_chunks': len(all_transcripts),\n",
        "                    'transcription_method': 'google_cloud_speech_chunks',\n",
        "                    'language': 'en',\n",
        "                    'transcript_length': len(full_transcript),\n",
        "                    'processed_at': datetime.now().isoformat(),\n",
        "                    'sample_rate': all_transcripts[0]['sample_rate'] if all_transcripts else 16000\n",
        "                }\n",
        "            )\n",
        "\n",
        "            content_hash = hashlib.md5(full_transcript.encode()).hexdigest()\n",
        "\n",
        "            logger.info(f\"✅ Full transcription completed: {len(full_transcript)} characters from {len(all_transcripts)} chunks\")\n",
        "\n",
        "            # Cleanup chunk files\n",
        "            for chunk_path in audio_chunks:\n",
        "                if chunk_path != file_identifier:  # Don't delete original file\n",
        "                    try:\n",
        "                        os.remove(chunk_path)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "            return [doc], content_hash\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Audio transcription failed: {e}\")\n",
        "            return self._create_sample_documents(file_identifier), \"sample\"\n",
        "\n",
        "    def _create_sample_documents(self, source_file: str) -> List[Document]:\n",
        "        \"\"\"Create sample documents for testing\"\"\"\n",
        "        sample_content = \"\"\"\n",
        "        This is a sample transcription of an audio file about machine learning and artificial intelligence.\n",
        "        The speaker discusses the fundamentals of neural networks and their applications in modern technology.\n",
        "        Key topics include deep learning, data preprocessing, model training, and real-world applications.\n",
        "        The discussion covers both theoretical concepts and practical implementation strategies.\n",
        "        \"\"\"\n",
        "\n",
        "        document = Document(\n",
        "            page_content=sample_content,\n",
        "            metadata={\n",
        "                'source': source_file,\n",
        "                'title': 'Sample Audio Transcription',\n",
        "                'transcription_method': 'sample',\n",
        "                'duration': 300,\n",
        "                'processed_at': datetime.now().isoformat()\n",
        "            }\n",
        "        )\n",
        "        return [document]\n",
        "\n",
        "    def create_text_chunks(self, documents: List[Document], chunk_size: int = 1500) -> List[Document]:\n",
        "        \"\"\"Create text chunks from transcribed documents\"\"\"\n",
        "        all_chunks = []\n",
        "\n",
        "        for doc in documents:\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=chunk_size,\n",
        "                chunk_overlap=200,\n",
        "                length_function=len,\n",
        "                separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        "            )\n",
        "\n",
        "            chunks = text_splitter.split_documents([doc])\n",
        "\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                chunk.metadata.update({\n",
        "                    'chunk_index': i,\n",
        "                    'total_chunks': len(chunks),\n",
        "                    'chunk_size': len(chunk.page_content)\n",
        "                })\n",
        "                all_chunks.append(chunk)\n",
        "\n",
        "        logger.info(f\"📊 Created {len(all_chunks)} text chunks\")\n",
        "        return all_chunks\n",
        "\n",
        "print(\"✅ Cell 1 Complete: Audio upload and processing system loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6L3Y1QXWPVup",
        "outputId": "e41ffde0-c96f-403b-f443-a20c297e599d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 2 Complete: AudioProcessingManager methods added!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 2: AudioProcessingManager Methods\n",
        "\n",
        "def create_comprehensive_summary(self, file_identifier: str, documents: List[Document]) -> Dict:\n",
        "    \"\"\"Create multi-level comprehensive summary\"\"\"\n",
        "    logger.info(f\"📝 Creating comprehensive summary for {file_identifier}\")\n",
        "\n",
        "    # Step 1: Individual chunk summaries\n",
        "    chunk_summaries = []\n",
        "    for i, doc in enumerate(documents):\n",
        "        try:\n",
        "            # Create synthetic timestamps for chunks that don't have them\n",
        "            start_time = doc.metadata.get('start_time', f\"Segment {i+1}\")\n",
        "            end_time = doc.metadata.get('end_time', f\"Segment {i+1}\")\n",
        "\n",
        "            chunk_prompt = ChatPromptTemplate.from_template(\n",
        "                \"\"\"Provide a comprehensive summary of this audio segment. Include:\n",
        "                1. Key points discussed\n",
        "                2. Important details and context\n",
        "                3. Any specific examples or explanations given\n",
        "                4. Concepts or topics introduced\n",
        "\n",
        "                Segment: {start_time} - {end_time}\n",
        "                Content: {content}\n",
        "\n",
        "                Create a detailed summary that preserves all important information:\"\"\"\n",
        "            )\n",
        "\n",
        "            summary_response = llm.invoke(\n",
        "                chunk_prompt.format_prompt(\n",
        "                    start_time=start_time,\n",
        "                    end_time=end_time,\n",
        "                    content=doc.page_content\n",
        "                ).to_string()\n",
        "            )\n",
        "\n",
        "            chunk_summaries.append({\n",
        "                'start_time': start_time,\n",
        "                'end_time': end_time,\n",
        "                'summary': summary_response.content,\n",
        "                'chunk_index': i+1,\n",
        "                'content_length': len(doc.page_content)\n",
        "            })\n",
        "\n",
        "            logger.info(f\"✅ Completed chunk summary {i+1}/{len(documents)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Failed to summarize chunk {i+1}: {e}\")\n",
        "            chunk_summaries.append({\n",
        "                'start_time': f\"Segment {i+1}\",\n",
        "                'end_time': f\"Segment {i+1}\",\n",
        "                'summary': f\"Summary unavailable for this segment (Segment {i+1})\",\n",
        "                'chunk_index': i+1,\n",
        "                'content_length': len(doc.page_content) if hasattr(doc, 'page_content') else 0\n",
        "            })\n",
        "\n",
        "    # Step 2: Create master summary from chunk summaries\n",
        "    try:\n",
        "        all_summaries = \"\\n\\n\".join([\n",
        "            f\"**Segment {summary['chunk_index']} ({summary['start_time']} - {summary['end_time']}):**\\n{summary['summary']}\"\n",
        "            for summary in chunk_summaries\n",
        "        ])\n",
        "\n",
        "        master_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"Based on these detailed segment summaries, create a comprehensive master summary that:\n",
        "\n",
        "            1. **OVERVIEW**: Provide a high-level overview of the entire audio content\n",
        "            2. **DETAILED CHRONOLOGICAL SUMMARY**: Create a detailed walkthrough preserving all important information\n",
        "            3. **KEY INSIGHTS**: Extract the most important insights and takeaways\n",
        "            4. **TOPICS BREAKDOWN**: Organize content by major topics/themes\n",
        "            5. **CONCLUSION**: Summarize final conclusions and implications\n",
        "\n",
        "            **IMPORTANT**: Do not lose any important context or details. Be comprehensive rather than brief.\n",
        "\n",
        "            Segment Summaries:\n",
        "            {all_summaries}\n",
        "\n",
        "            Comprehensive Master Summary:\"\"\"\n",
        "        )\n",
        "\n",
        "        master_response = llm.invoke(\n",
        "            master_prompt.format_prompt(all_summaries=all_summaries).to_string()\n",
        "        )\n",
        "\n",
        "        logger.info(\"✅ Created master comprehensive summary\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Failed to create master summary: {e}\")\n",
        "        master_response = type('obj', (object,), {'content': \"Master summary generation failed\"})\n",
        "\n",
        "    return {\n",
        "        'chunk_summaries': chunk_summaries,\n",
        "        'master_summary': master_response.content,\n",
        "        'total_chunks': len(chunk_summaries),\n",
        "        'total_content_length': sum([s['content_length'] for s in chunk_summaries])\n",
        "    }\n",
        "\n",
        "def add_or_update_audio(self, file_path: str) -> bool:\n",
        "    \"\"\"Add new audio file or update existing one\"\"\"\n",
        "    logger.info(f\"\\n🔄 Processing audio file: {file_path}\")\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        logger.error(\"❌ File not found\")\n",
        "        return False\n",
        "\n",
        "    # Get file info\n",
        "    audio_info = get_audio_info(file_path)\n",
        "    file_identifier = os.path.basename(file_path)\n",
        "\n",
        "    # Check if file changed\n",
        "    file_hash = hashlib.md5(open(file_path, 'rb').read()).hexdigest()\n",
        "    if file_identifier in self.audio_hashes:\n",
        "        if self.audio_hashes[file_identifier] == file_hash:\n",
        "            logger.info(\"📋 File unchanged, using cached summaries\")\n",
        "            return True\n",
        "\n",
        "    # Split large audio files\n",
        "    try:\n",
        "        audio_chunks = self.split_large_audio(file_path)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Audio splitting failed: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Transcribe audio chunks\n",
        "    documents, content_hash = self.transcribe_audio_chunks(audio_chunks, file_identifier)\n",
        "\n",
        "    if not documents:\n",
        "        logger.error(\"❌ No transcription available\")\n",
        "        return False\n",
        "\n",
        "    # Create text chunks\n",
        "    chunks = self.create_text_chunks(documents)\n",
        "\n",
        "    if not chunks:\n",
        "        logger.error(\"❌ No chunks created\")\n",
        "        return False\n",
        "\n",
        "    # Add metadata to chunks\n",
        "    for doc in chunks:\n",
        "        doc.metadata.update({\n",
        "            'source_file': file_path,\n",
        "            'file_identifier': file_identifier,\n",
        "            'content_hash': content_hash,\n",
        "            'processed_at': datetime.now().isoformat(),\n",
        "            'audio_info': audio_info\n",
        "        })\n",
        "\n",
        "    # Create comprehensive summary\n",
        "    summary_data = self.create_comprehensive_summary(file_identifier, chunks)\n",
        "\n",
        "    # Create vector store if embeddings available\n",
        "    if self.embeddings:\n",
        "        try:\n",
        "            # Create documents with summaries for vector search\n",
        "            summary_documents = []\n",
        "            for chunk_summary in summary_data['chunk_summaries']:\n",
        "                summary_doc = Document(\n",
        "                    page_content=chunk_summary['summary'],\n",
        "                    metadata={\n",
        "                        'source_file': file_path,\n",
        "                        'file_identifier': file_identifier,\n",
        "                        'start_time': chunk_summary['start_time'],\n",
        "                        'end_time': chunk_summary['end_time'],\n",
        "                        'content_type': 'chunk_summary'\n",
        "                    }\n",
        "                )\n",
        "                summary_documents.append(summary_doc)\n",
        "\n",
        "            # Add master summary\n",
        "            master_doc = Document(\n",
        "                page_content=summary_data['master_summary'],\n",
        "                metadata={\n",
        "                    'source_file': file_path,\n",
        "                    'file_identifier': file_identifier,\n",
        "                    'content_type': 'master_summary'\n",
        "                }\n",
        "            )\n",
        "            summary_documents.append(master_doc)\n",
        "\n",
        "            # Create vector store\n",
        "            vector_store = FAISS.from_documents(summary_documents, self.embeddings)\n",
        "            self.audio_stores[file_identifier] = vector_store\n",
        "\n",
        "            # Rebuild merged store\n",
        "            self._rebuild_merged_store()\n",
        "\n",
        "            logger.info(\"✅ Created vector store for audio summaries\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"⚠️ Vector store creation failed: {e}\")\n",
        "\n",
        "    # Store metadata\n",
        "    self.audio_metadata[file_identifier] = {\n",
        "        'file_path': file_path,\n",
        "        'chunks_count': len(chunks),\n",
        "        'summary_data': summary_data,\n",
        "        'last_updated': datetime.now().isoformat(),\n",
        "        'content_hash': content_hash,\n",
        "        'audio_info': audio_info\n",
        "    }\n",
        "\n",
        "    # Update tracking\n",
        "    self.audio_hashes[file_identifier] = file_hash\n",
        "    if file_identifier not in self.current_files:\n",
        "        self.current_files.append(file_identifier)\n",
        "\n",
        "    self._save_cache()\n",
        "\n",
        "    logger.info(f\"✅ Successfully processed audio file: {file_identifier}\")\n",
        "    return True\n",
        "\n",
        "def _rebuild_merged_store(self):\n",
        "    \"\"\"Rebuild the merged vector store from all individual stores\"\"\"\n",
        "    if not self.audio_stores:\n",
        "        self.merged_store = None\n",
        "        return\n",
        "\n",
        "    logger.info(\"🔗 Rebuilding merged vector store...\")\n",
        "\n",
        "    stores = list(self.audio_stores.values())\n",
        "    self.merged_store = stores[0]\n",
        "\n",
        "    for store in stores[1:]:\n",
        "        self.merged_store.merge_from(store)\n",
        "\n",
        "    logger.info(f\"✅ Merged store ready with {len(self.current_files)} audio sources\")\n",
        "\n",
        "def get_retriever(self, k: int = 5):\n",
        "    \"\"\"Get retriever from merged store\"\"\"\n",
        "    if self.merged_store is None:\n",
        "        raise ValueError(\"No vector store available. Add audio files first.\")\n",
        "    return self.merged_store.as_retriever(search_kwargs={\"k\": k})\n",
        "\n",
        "def get_memory_info(self) -> Dict:\n",
        "    \"\"\"Get information about current memory state\"\"\"\n",
        "    total_duration = 0\n",
        "    total_chunks = 0\n",
        "\n",
        "    for audio_data in self.audio_metadata.values():\n",
        "        if 'audio_info' in audio_data:\n",
        "            total_duration += audio_data['audio_info'].get('duration_seconds', 0)\n",
        "        if 'summary_data' in audio_data:\n",
        "            total_chunks += audio_data['summary_data'].get('total_chunks', 0)\n",
        "\n",
        "    return {\n",
        "        'active_files': self.current_files,\n",
        "        'total_files': len(self.audio_stores),\n",
        "        'total_duration_minutes': round(total_duration / 60, 2),\n",
        "        'total_chunks': total_chunks,\n",
        "        'metadata': self.audio_metadata,\n",
        "        'file_hashes': self.audio_hashes\n",
        "    }\n",
        "\n",
        "def remove_audio(self, file_identifier: str) -> bool:\n",
        "    \"\"\"Remove audio file from memory and rebuild\"\"\"\n",
        "    if file_identifier in self.audio_stores:\n",
        "        del self.audio_stores[file_identifier]\n",
        "        del self.audio_metadata[file_identifier]\n",
        "        if file_identifier in self.current_files:\n",
        "            self.current_files.remove(file_identifier)\n",
        "        if file_identifier in self.audio_hashes:\n",
        "            del self.audio_hashes[file_identifier]\n",
        "\n",
        "        self._rebuild_merged_store()\n",
        "        self._save_cache()\n",
        "        logger.info(f\"🗑️ Removed {file_identifier} from memory\")\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def get_audio_summary(self, file_identifier: str) -> Optional[Dict]:\n",
        "    \"\"\"Get comprehensive summary for specific audio file\"\"\"\n",
        "    if file_identifier in self.audio_metadata:\n",
        "        return self.audio_metadata[file_identifier].get('summary_data')\n",
        "    return None\n",
        "\n",
        "# Add all methods to the AudioProcessingManager class\n",
        "AudioProcessingManager.create_comprehensive_summary = create_comprehensive_summary\n",
        "AudioProcessingManager.add_or_update_audio = add_or_update_audio\n",
        "AudioProcessingManager._rebuild_merged_store = _rebuild_merged_store\n",
        "AudioProcessingManager.get_retriever = get_retriever\n",
        "AudioProcessingManager.get_memory_info = get_memory_info\n",
        "AudioProcessingManager.remove_audio = remove_audio\n",
        "AudioProcessingManager.get_audio_summary = get_audio_summary\n",
        "AudioProcessingManager.get_audio_properties = get_audio_properties\n",
        "\n",
        "# Initialize the audio processing manager\n",
        "if embeddings:\n",
        "    audio_manager = AudioProcessingManager(embeddings)\n",
        "else:\n",
        "    audio_manager = AudioProcessingManager(None)\n",
        "\n",
        "print(\"✅ Cell 2 Complete: AudioProcessingManager methods added!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1SvAnsSuxg3",
        "outputId": "e2fd51cc-1e22-43ea-eda0-2b9a530bc78d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 SYSTEM REQUIREMENTS CHECK:\n",
            "✅ LangChain and Gemini: Available\n",
            "✅ Audio Processing (pydub): Available\n",
            "✅ Google Cloud Speech: Available\n",
            "✅ HuggingFace Embeddings: Available\n",
            "✅ Google Colab File Upload: Available\n",
            "\n",
            "🔑 Gemini API Key: ✅ Configured\n",
            "\n",
            "✅ Cell 3 Complete: System ready!\n",
            "🚀 Run: run_audio_processing_system() to start the interactive system\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 3: Interactive Audio Processing System\n",
        "\n",
        "def audio_qa_pipeline(question: str):\n",
        "    \"\"\"Enhanced Q&A pipeline for audio content\"\"\"\n",
        "    if not audio_manager.current_files:\n",
        "        print(\"❌ No audio files loaded. Please upload audio files first.\")\n",
        "        return\n",
        "\n",
        "    print(f\"❓ Question: {question}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get memory info\n",
        "    memory_info = audio_manager.get_memory_info()\n",
        "\n",
        "    try:\n",
        "        if audio_manager.embeddings and audio_manager.merged_store:\n",
        "            # Use vector search\n",
        "            retriever = audio_manager.get_retriever(k=5)\n",
        "            retrieved_docs = retriever.invoke(question)\n",
        "\n",
        "            context = \"\"\n",
        "            for doc in retrieved_docs:\n",
        "                source = doc.metadata.get('file_identifier', 'Unknown')\n",
        "                content_type = doc.metadata.get('content_type', 'unknown')\n",
        "\n",
        "                if content_type == 'chunk_summary':\n",
        "                    time_info = f\"[{doc.metadata.get('start_time', 'Unknown')} - {doc.metadata.get('end_time', 'Unknown')}]\"\n",
        "                    context += f\"\\n**Audio: {source} {time_info}**\\n{doc.page_content}\\n\"\n",
        "                else:\n",
        "                    context += f\"\\n**Audio: {source} (Master Summary)**\\n{doc.page_content}\\n\"\n",
        "\n",
        "            print(\"📄 Retrieved Context Preview:\")\n",
        "            preview = context[:500] + \"...\" if len(context) > 500 else context\n",
        "            print(preview)\n",
        "            print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "        else:\n",
        "            # Fallback: use all summaries\n",
        "            context = \"\"\n",
        "            for file_id in memory_info['active_files']:\n",
        "                summary_data = audio_manager.get_audio_summary(file_id)\n",
        "                if summary_data:\n",
        "                    context += f\"\\n**Audio: {file_id}**\\n{summary_data['master_summary']}\\n\"\n",
        "\n",
        "        # Generate answer\n",
        "        answer_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"Answer the following question based on the audio content provided:\n",
        "\n",
        "            Context from Audio Files:\n",
        "            {context}\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Provide a comprehensive answer that:\n",
        "            1. Directly addresses the question\n",
        "            2. References specific audio files and segments when relevant\n",
        "            3. Synthesizes information from multiple sources if applicable\n",
        "            4. Includes relevant details and context\n",
        "\n",
        "            Answer:\"\"\"\n",
        "        )\n",
        "\n",
        "        final_answer = llm.invoke(\n",
        "            answer_prompt.format_prompt(\n",
        "                context=context,\n",
        "                question=question\n",
        "            ).to_string()\n",
        "        ).content\n",
        "\n",
        "        print(\"💡 Answer:\")\n",
        "        print(final_answer)\n",
        "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "        return final_answer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during Q&A: {e}\")\n",
        "        return None\n",
        "\n",
        "def display_audio_summary(file_identifier: str):\n",
        "    \"\"\"Display comprehensive summary for a specific audio file\"\"\"\n",
        "    summary_data = audio_manager.get_audio_summary(file_identifier)\n",
        "\n",
        "    if not summary_data:\n",
        "        print(f\"❌ No summary available for {file_identifier}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n🎵 COMPREHENSIVE SUMMARY: {file_identifier}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"📊 SUMMARY STATISTICS:\")\n",
        "    print(f\"  Total Chunks: {summary_data['total_chunks']}\")\n",
        "    print(f\"  Total Content Length: {summary_data['total_content_length']} characters\")\n",
        "\n",
        "    print(\"\\n📝 MASTER SUMMARY:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(summary_data['master_summary'])\n",
        "\n",
        "    print(f\"\\n🕐 DETAILED SEGMENTS ({len(summary_data['chunk_summaries'])} segments):\")\n",
        "    print(\"-\" * 40)\n",
        "    for i, chunk in enumerate(summary_data['chunk_summaries']):\n",
        "        print(f\"\\n⏰ {chunk['start_time']} - {chunk['end_time']}:\")\n",
        "        print(chunk['summary'])\n",
        "\n",
        "        if i < len(summary_data['chunk_summaries']) - 1:\n",
        "            print(\"\\n\" + \"·\" * 40)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "def compare_audio_files(topic: str):\n",
        "    \"\"\"Compare how different audio files discuss a specific topic\"\"\"\n",
        "    if not audio_manager.current_files:\n",
        "        print(\"❌ No audio files loaded for comparison\")\n",
        "        return\n",
        "\n",
        "    print(f\"🔍 Comparing audio files on topic: {topic}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    comparison_context = \"\"\n",
        "\n",
        "    for file_id in audio_manager.current_files:\n",
        "        summary_data = audio_manager.get_audio_summary(file_id)\n",
        "        if summary_data:\n",
        "            comparison_context += f\"\\n**Audio File: {file_id}**\\n\"\n",
        "            comparison_context += f\"Summary: {summary_data['master_summary']}\\n\"\n",
        "            comparison_context += \"-\" * 40 + \"\\n\"\n",
        "\n",
        "    try:\n",
        "        comparison_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"Compare how these different audio files discuss the topic \"{topic}\":\n",
        "\n",
        "            {comparison_context}\n",
        "\n",
        "            Provide a comprehensive comparison that:\n",
        "            1. Identifies common themes and approaches\n",
        "            2. Highlights unique perspectives from each audio file\n",
        "            3. Notes any contradictions or different viewpoints\n",
        "            4. Synthesizes the information into key insights\n",
        "            5. Mentions which files provide the most depth on specific aspects\n",
        "\n",
        "            Comparison Analysis:\"\"\"\n",
        "        )\n",
        "\n",
        "        comparison_response = llm.invoke(\n",
        "            comparison_prompt.format_prompt(\n",
        "                topic=topic,\n",
        "                comparison_context=comparison_context\n",
        "            ).to_string()\n",
        "        )\n",
        "\n",
        "        print(\"📊 Audio File Comparison Analysis:\")\n",
        "        print(comparison_response.content)\n",
        "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during comparison: {e}\")\n",
        "\n",
        "def export_summaries():\n",
        "    \"\"\"Export all summaries to a file\"\"\"\n",
        "    if not audio_manager.current_files:\n",
        "        print(\"❌ No audio files to export\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        export_data = {\n",
        "            'export_timestamp': datetime.now().isoformat(),\n",
        "            'total_files': len(audio_manager.current_files),\n",
        "            'audio_files': {}\n",
        "        }\n",
        "\n",
        "        for file_id in audio_manager.current_files:\n",
        "            summary_data = audio_manager.get_audio_summary(file_id)\n",
        "            metadata = audio_manager.audio_metadata.get(file_id, {})\n",
        "\n",
        "            export_data['audio_files'][file_id] = {\n",
        "                'metadata': metadata,\n",
        "                'summary_data': summary_data\n",
        "            }\n",
        "\n",
        "        export_filename = f\"audio_summaries_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "\n",
        "        with open(export_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"✅ Exported summaries to: {export_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Export failed: {e}\")\n",
        "\n",
        "def show_system_stats():\n",
        "    \"\"\"Show detailed system statistics\"\"\"\n",
        "    info = audio_manager.get_memory_info()\n",
        "\n",
        "    print(\"📊 SYSTEM STATISTICS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"🎵 Total Audio Files Loaded: {len(info['active_files'])}\")\n",
        "    print(f\"⏱️  Total Content Duration: {info['total_duration_minutes']:.1f} minutes\")\n",
        "    print(f\"📝 Total Summary Chunks: {info['total_chunks']}\")\n",
        "    print(f\"💾 Cache Directory: {audio_manager.cache_dir}\")\n",
        "\n",
        "    if audio_manager.embeddings:\n",
        "        print(f\"🔍 Vector Search: Enabled\")\n",
        "        print(f\"📊 Vector Stores: {len(audio_manager.audio_stores)}\")\n",
        "    else:\n",
        "        print(f\"🔍 Vector Search: Disabled (embeddings not available)\")\n",
        "\n",
        "    print(f\"🗄️  Audio Processing: {'Available' if AUDIO_PROCESSING_AVAILABLE else 'Not Available'}\")\n",
        "    print(f\"🎤 Google Cloud Speech: {'Available' if GOOGLE_CLOUD_SPEECH_AVAILABLE else 'Not Available'}\")\n",
        "\n",
        "    print(\"\\n📈 PER-FILE BREAKDOWN:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for file_id in info['active_files']:\n",
        "        metadata = info['metadata'].get(file_id, {})\n",
        "        summary_data = metadata.get('summary_data', {})\n",
        "        audio_info = metadata.get('audio_info', {})\n",
        "\n",
        "        duration = audio_info.get('duration_minutes', 0)\n",
        "        chunks = summary_data.get('total_chunks', 0)\n",
        "\n",
        "        print(f\"🎵 {file_id}\")\n",
        "        print(f\"   Duration: {duration:.1f} min | Chunks: {chunks}\")\n",
        "        print(f\"   Size: {audio_info.get('file_size_mb', 0):.1f} MB\")\n",
        "\n",
        "# Interactive system\n",
        "def run_audio_processing_system():\n",
        "    \"\"\"Run the interactive audio processing system\"\"\"\n",
        "    print(\"🚀 Audio Processing & Q&A System\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"📋 BASIC COMMANDS:\")\n",
        "    print(\"  upload                - Upload new audio file for processing\")\n",
        "    print(\"  process <filename>    - Process uploaded audio file\")\n",
        "    print(\"  remove <filename>     - Remove audio file from memory\")\n",
        "    print(\"  summary <filename>    - Show detailed summary of specific file\")\n",
        "    print(\"  summaries            - Show summaries of all loaded files\")\n",
        "    print(\"\\n🔍 ANALYSIS COMMANDS:\")\n",
        "    print(\"  memory               - Show memory status and statistics\")\n",
        "    print(\"  sources              - List active audio sources\")\n",
        "    print(\"  search <query>       - Search across all audio summaries\")\n",
        "    print(\"  compare <topic>      - Compare how files discuss a topic\")\n",
        "    print(\"  stats                - Show detailed system statistics\")\n",
        "    print(\"\\n💾 UTILITY COMMANDS:\")\n",
        "    print(\"  export               - Export all summaries to JSON file\")\n",
        "    print(\"  clear                - Clear all loaded files\")\n",
        "    print(\"  help                 - Show this help message\")\n",
        "    print(\"  quit                 - Exit system\")\n",
        "    print(\"\\n❓ QUESTIONS:\")\n",
        "    print(\"  <question>           - Ask any question about loaded audio files\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Check system requirements\n",
        "    if not AUDIO_PROCESSING_AVAILABLE:\n",
        "        print(\"\\n⚠️  WARNING: pydub not available. Audio splitting disabled.\")\n",
        "    if not GOOGLE_CLOUD_SPEECH_AVAILABLE:\n",
        "        print(\"⚠️  WARNING: Google Cloud Speech not available. Using sample data.\")\n",
        "\n",
        "    print(f\"\\n🏠 Cache Directory: {audio_manager.cache_dir}\")\n",
        "    print(\"💡 TIP: Start by uploading an audio file with: upload\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\n🎯 Enter command or question: \").strip()\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"👋 Thanks for using the Audio Processing Q&A system!\")\n",
        "            break\n",
        "\n",
        "        elif user_input.lower() in ['help', 'h']:\n",
        "            print(\"📋 Commands listed above. Try 'upload' to get started!\")\n",
        "\n",
        "        elif user_input.lower() == 'upload':\n",
        "            file_path = input(\"📁 Enter the path to your audio file: \").strip()\n",
        "            if file_path and os.path.exists(file_path):\n",
        "                success = audio_manager.add_or_update_audio(file_path)\n",
        "                if success:\n",
        "                    print(f\"✅ Successfully processed: {file_path}\")\n",
        "                else:\n",
        "                    print(f\"❌ Failed to process: {file_path}\")\n",
        "            else:\n",
        "                print(\"❌ File not found or no path provided\")\n",
        "\n",
        "        elif user_input.startswith('add '):\n",
        "            file_path = user_input[4:].strip()\n",
        "            if file_path and os.path.exists(file_path):\n",
        "                success = audio_manager.add_or_update_audio(file_path)\n",
        "                if success:\n",
        "                    print(f\"✅ Successfully processed: {file_path}\")\n",
        "                else:\n",
        "                    print(f\"❌ Failed to process: {file_path}\")\n",
        "            else:\n",
        "                print(\"❌ File not found or invalid path\")\n",
        "\n",
        "        elif user_input.startswith('process '):\n",
        "            filename = user_input[8:].strip()\n",
        "            if filename and os.path.exists(filename):\n",
        "                success = audio_manager.add_or_update_audio(filename)\n",
        "                if success:\n",
        "                    print(f\"✅ Successfully processed: {filename}\")\n",
        "                else:\n",
        "                    print(f\"❌ Failed to process: {filename}\")\n",
        "            else:\n",
        "                print(\"❌ File not found or no filename provided\")\n",
        "\n",
        "        elif user_input.startswith('remove '):\n",
        "            filename = user_input[7:].strip()\n",
        "            if filename:\n",
        "                success = audio_manager.remove_audio(filename)\n",
        "                if success:\n",
        "                    print(f\"✅ Successfully removed: {filename}\")\n",
        "                else:\n",
        "                    print(f\"❌ File not found: {filename}\")\n",
        "            else:\n",
        "                print(\"❌ Please provide a filename\")\n",
        "\n",
        "        elif user_input.startswith('summary '):\n",
        "            filename = user_input[8:].strip()\n",
        "            if filename:\n",
        "                display_audio_summary(filename)\n",
        "            else:\n",
        "                print(\"❌ Please provide a filename\")\n",
        "\n",
        "        elif user_input.lower() == 'summaries':\n",
        "            info = audio_manager.get_memory_info()\n",
        "            if info['active_files']:\n",
        "                for file_id in info['active_files']:\n",
        "                    display_audio_summary(file_id)\n",
        "            else:\n",
        "                print(\"❌ No audio files loaded. Upload files first with 'upload'\")\n",
        "\n",
        "        elif user_input.lower() == 'memory':\n",
        "            info = audio_manager.get_memory_info()\n",
        "            print(\"🧠 Memory Status:\")\n",
        "            print(f\"  Active Files: {len(info['active_files'])}\")\n",
        "            print(f\"  Total Duration: {info['total_duration_minutes']} minutes\")\n",
        "            print(f\"  Total Chunks: {info['total_chunks']}\")\n",
        "\n",
        "            if info['active_files']:\n",
        "                print(\"\\n🎵 Loaded Audio Files:\")\n",
        "                for file_id, metadata in info['metadata'].items():\n",
        "                    chunks = metadata.get('chunks_count', 0)\n",
        "                    audio_info = metadata.get('audio_info', {})\n",
        "                    duration = audio_info.get('duration_formatted', 'Unknown')\n",
        "                    print(f\"    🎵 {file_id}\")\n",
        "                    print(f\"        Duration: {duration} | Chunks: {chunks}\")\n",
        "\n",
        "        elif user_input.lower() == 'sources':\n",
        "            info = audio_manager.get_memory_info()\n",
        "            if info['active_files']:\n",
        "                print(\"🎵 Active Audio Sources:\")\n",
        "                for i, file_id in enumerate(info['active_files'], 1):\n",
        "                    metadata = info['metadata'].get(file_id, {})\n",
        "                    audio_info = metadata.get('audio_info', {})\n",
        "                    duration = audio_info.get('duration_formatted', 'Unknown')\n",
        "                    size = audio_info.get('file_size_mb', 0)\n",
        "                    print(f\"  {i}. {file_id}\")\n",
        "                    print(f\"     Duration: {duration} | Size: {size:.1f} MB\")\n",
        "            else:\n",
        "                print(\"❌ No audio files loaded. Upload files first with 'upload'\")\n",
        "\n",
        "        elif user_input.startswith('search '):\n",
        "            query = user_input[7:].strip()\n",
        "            if query:\n",
        "                audio_qa_pipeline(query)\n",
        "            else:\n",
        "                print(\"❌ Please provide a search query\")\n",
        "\n",
        "        elif user_input.startswith('compare '):\n",
        "            topic = user_input[8:].strip()\n",
        "            if topic:\n",
        "                compare_audio_files(topic)\n",
        "            else:\n",
        "                print(\"❌ Please provide a topic to compare\")\n",
        "\n",
        "        elif user_input.lower() == 'stats':\n",
        "            show_system_stats()\n",
        "\n",
        "        elif user_input.lower() == 'export':\n",
        "            export_summaries()\n",
        "\n",
        "        elif user_input.lower() == 'clear':\n",
        "            confirm = input(\"⚠️  Are you sure you want to clear all audio files? (yes/no): \")\n",
        "            if confirm.lower() in ['yes', 'y']:\n",
        "                for file_id in list(audio_manager.current_files):\n",
        "                    audio_manager.remove_audio(file_id)\n",
        "                print(\"✅ All audio files cleared from memory\")\n",
        "            else:\n",
        "                print(\"❌ Clear operation cancelled\")\n",
        "\n",
        "        elif user_input:\n",
        "            try:\n",
        "                if audio_manager.current_files:\n",
        "                    audio_qa_pipeline(user_input)\n",
        "                else:\n",
        "                    print(\"❌ No audio files loaded. Please upload audio files first with 'upload'\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error: {e}\")\n",
        "                print(\"💡 Try rephrasing your question or check if files are properly loaded\")\n",
        "        else:\n",
        "            print(\"❓ Please enter a valid command or question. Type 'help' for available commands.\")\n",
        "\n",
        "# System check and startup\n",
        "print(\"🔧 SYSTEM REQUIREMENTS CHECK:\")\n",
        "print(f\"✅ LangChain and Gemini: Available\")\n",
        "print(f\"{'✅' if AUDIO_PROCESSING_AVAILABLE else '❌'} Audio Processing (pydub): {'Available' if AUDIO_PROCESSING_AVAILABLE else 'Not Available'}\")\n",
        "print(f\"{'✅' if GOOGLE_CLOUD_SPEECH_AVAILABLE else '❌'} Google Cloud Speech: {'Available' if GOOGLE_CLOUD_SPEECH_AVAILABLE else 'Not Available'}\")\n",
        "print(f\"{'✅' if EMBEDDINGS_AVAILABLE else '❌'} HuggingFace Embeddings: {'Available' if EMBEDDINGS_AVAILABLE else 'Not Available'}\")\n",
        "print(f\"{'✅' if COLAB_AVAILABLE else '❌'} Google Colab File Upload: {'Available' if COLAB_AVAILABLE else 'Not Available'}\")\n",
        "\n",
        "if not AUDIO_PROCESSING_AVAILABLE:\n",
        "    print(\"\\n📦 To install audio processing:\")\n",
        "    print(\"   pip install pydub\")\n",
        "\n",
        "if not GOOGLE_CLOUD_SPEECH_AVAILABLE:\n",
        "    print(\"\\n📦 To install Google Cloud Speech:\")\n",
        "    print(\"   pip install google-cloud-speech\")\n",
        "\n",
        "if not EMBEDDINGS_AVAILABLE:\n",
        "    print(\"\\n📦 To install embedding support:\")\n",
        "    print(\"   pip install sentence-transformers\")\n",
        "\n",
        "print(f\"\\n🔑 Gemini API Key: {'✅ Configured' if os.getenv('GOOGLE_API_KEY') else '❌ Missing'}\")\n",
        "\n",
        "if not os.getenv('GOOGLE_API_KEY'):\n",
        "    print(\"⚠️  Please set GOOGLE_API_KEY in your .env file\")\n",
        "else:\n",
        "    print(\"\\n✅ Cell 3 Complete: System ready!\")\n",
        "    print(\"🚀 Run: run_audio_processing_system() to start the interactive system\")\n",
        "\n",
        "# Uncomment the line below to auto-start the system\n",
        "# run_audio_processing_system()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DqIe0So8u-kq",
        "outputId": "12cf05ec-2a56-43e2-8d2a-d1a5ad99233c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Audio Processing & Q&A System\n",
            "================================================================================\n",
            "📋 BASIC COMMANDS:\n",
            "  upload                - Upload new audio file for processing\n",
            "  process <filename>    - Process uploaded audio file\n",
            "  remove <filename>     - Remove audio file from memory\n",
            "  summary <filename>    - Show detailed summary of specific file\n",
            "  summaries            - Show summaries of all loaded files\n",
            "\n",
            "🔍 ANALYSIS COMMANDS:\n",
            "  memory               - Show memory status and statistics\n",
            "  sources              - List active audio sources\n",
            "  search <query>       - Search across all audio summaries\n",
            "  compare <topic>      - Compare how files discuss a topic\n",
            "  stats                - Show detailed system statistics\n",
            "\n",
            "💾 UTILITY COMMANDS:\n",
            "  export               - Export all summaries to JSON file\n",
            "  clear                - Clear all loaded files\n",
            "  help                 - Show this help message\n",
            "  quit                 - Exit system\n",
            "\n",
            "❓ QUESTIONS:\n",
            "  <question>           - Ask any question about loaded audio files\n",
            "================================================================================\n",
            "\n",
            "🏠 Cache Directory: ./audio_cache\n",
            "💡 TIP: Start by uploading an audio file with: upload\n",
            "\n",
            "🎯 Enter command or question: memory\n",
            "🧠 Memory Status:\n",
            "  Active Files: 1\n",
            "  Total Duration: 1.49 minutes\n",
            "  Total Chunks: 1\n",
            "\n",
            "🎵 Loaded Audio Files:\n",
            "    🎵 LISTEN TO THIS BEFORE EVERY EXAM! Powerful Motivational Speech 2024.wav\n",
            "        Duration: 01:29 | Chunks: 1\n",
            "\n",
            "🎯 Enter command or question: Give a 1 line summary\n",
            "❓ Question: Give a 1 line summary\n",
            "============================================================\n",
            "📄 Retrieved Context Preview:\n",
            "\n",
            "**Audio: LISTEN TO THIS BEFORE EVERY EXAM! Powerful Motivational Speech 2024.wav [Segment 1 - Segment 1]**\n",
            "This audio segment addresses the anxieties and challenges students face when preparing for exams.  It uses the metaphor of climbing a mountain to represent the arduous process of studying.\n",
            "\n",
            "**1. Key Points Discussed:**\n",
            "\n",
            "* **The struggle of exam preparation:** The segment acknowledges the common experience of feeling overwhelmed, stuck, and pressured while studying.\n",
            "* **Shifting perspective...\n",
            "\n",
            "============================================================\n",
            "\n",
            "💡 Answer:\n",
            "This motivational audio (\"LISTEN TO THIS BEFORE EVERY EXAM! Powerful Motivational Speech 2024.wav\") uses the metaphor of climbing a mountain to encourage students to overcome exam anxiety by adopting a positive mindset, committing to consistent effort, and visualizing success.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "🎯 Enter command or question: export\n",
            "✅ Exported summaries to: audio_summaries_20250907_075914.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3202195030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_audio_processing_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1511708803.py\u001b[0m in \u001b[0;36mrun_audio_processing_system\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n🎯 Enter command or question: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "run_audio_processing_system()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}